{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7578224",
   "metadata": {},
   "source": [
    "### Atividade 1 - Monte um passo a passo para o algoritmo Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8378d79",
   "metadata": {},
   "source": [
    "O Random Forest apresenta os seguintes passos:\n",
    "\n",
    "- Bootstrap + features selection: criação de amostras aleatórias de treinamento com reposição a partir do conjunto de dados de treinamento original. Essas novas amostras têm o mesmo número de linhas do conjunto de dados original e mas cada linha pode se repetir, umas vez que a amostragem com reposição permite que cada observação seja selecionada mais de uma vez.  <br> Além das linhas, também será feita uma amostragem aleatória de colunas. Considerando o número de colunas dos dados originais como `p` e dos subconjuntos como `m`, a escolha seria a seguinte: (1) para modelos de classificação: m = $\\sqrt{p}$ ; (2) para modelos de regressão: m = $\\frac{p}{3}$. \n",
    "- Modelagem: montagem de um modelo para cada amostra bootstrap criada, de forma independente. Esses modelos devem ser árvore de decisão.\n",
    "- Agregação (Aggregating): os resultados dos modelos individuais são agregados para formar uma única previsão, mais robusta e confiável. No caso de problemas de classificação, a agregação geralmente é feita por votação , onde a classe mais comum entre os modelos é selecionada. Para problemas de regressão, a agregação é feita calculando-se a média dos resultados dos modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fd713a",
   "metadata": {},
   "source": [
    "### Atividade 2 - Explique com suas palavras o Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e4f19c",
   "metadata": {},
   "source": [
    "O Random Forest é uma variação do Bagging, sendo também um exemplo de técnica de ensemble, em que modelos são combinados em um algoritmo com o objetivo de obter um modelo final, mais confiável e com melhores resultados. No caso do Random Forest, são criadas amostras com o mesmo número de linhas do dataset original, mas com número de colunas diferentes. Cada amostra será utilizada para treinar um modelo de forma independente e esse modelo deve ser uma árvore de decisão. No final, os modelos são agregados, dando origem a um modelo final mais robusto, que entenda melhor os dados e evite o overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3ef3df",
   "metadata": {},
   "source": [
    "### Atividade 3 - Qual a diferença entre Bagginge Random Forest?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea05fd9",
   "metadata": {},
   "source": [
    "A principal diferença entre as duas técnicas é a menor variância devido à uma menor correlação entre os subconjuntos no Random Forest. Uma vez que o número de colunas dos subconjuntos não é o mesmo do dataset original, há uma menor correlação entre eles, gerando um resultado mais robusto.\n",
    "No caso do Bagging, os subconjuntos são mais correlacionados, pois apresentam o mesmo número de linhas e colunas dos dados originais. <br>\n",
    "Além disso, no caso do Bagging os subconjuntos podem ser modelados de várias formas, no Random Forest devem ser árvores de decisão. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204d5aaf",
   "metadata": {},
   "source": [
    "### Atividade 4 - Implementar em python o código do Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8617a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd24e207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para realizar amostragem bootstrap\n",
    "\n",
    "def bootstrap_sampling(X, y):\n",
    "    n_samples = X.shape[0]\n",
    "    indices = np.random.randint(0, n_samples, size=n_samples)\n",
    "    return X[indices], y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "112f7e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para treinar uma árvore de decisão\n",
    "\n",
    "def train_decision_tree(X, y, max_depth=None):\n",
    "    tree = DecisionTreeClassifier(max_depth=max_depth)\n",
    "    tree.fit(X, y)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "996c051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para fazer previsões usando o conjunto de árvores de decisão\n",
    "\n",
    "def predict_forest(forest, X):\n",
    "    predictions = np.zeros((X.shape[0], len(forest)), dtype=int) #matriz para armazenar as previsões feitas por cada árvore de decisão\n",
    "    for i, tree in enumerate(forest):\n",
    "        predictions[:, i] = tree.predict(X)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06d61454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular a moda das previsões\n",
    "\n",
    "def calculate_mode(predictions):\n",
    "    return np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=1, arr=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "302047da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o conjunto de dados digits\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "# Dividindo o conjunto de dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definindo os parâmetros do Random Forest\n",
    "num_trees = 10\n",
    "max_depth = 5  # Profundidade máxima das árvores\n",
    "\n",
    "# Inicializando a lista para armazenar as árvores do Random Forest\n",
    "forest = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e103592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando cada árvore do Random Forest\n",
    "\n",
    "for _ in range(num_trees):\n",
    "    X_bootstrap, y_bootstrap = bootstrap_sampling(X_train, y_train)\n",
    "    tree = train_decision_tree(X_bootstrap, y_bootstrap, max_depth=max_depth)\n",
    "    forest.append(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3acb01d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo previsões usando o Random Forest\n",
    "\n",
    "predictions = predict_forest(forest, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72180100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando as previsões finais\n",
    "\n",
    "final_predictions = calculate_mode(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "679e4f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do Random Forest: 0.82\n"
     ]
    }
   ],
   "source": [
    "# Calculando a acurácia\n",
    "\n",
    "accuracy = accuracy_score(y_test, final_predictions)\n",
    "print(\"Acurácia do Random Forest:\", round(accuracy,2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
